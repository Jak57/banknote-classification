# Paper 1: 2022 (BRAC - Not Public)
Bangladeshi Paper Currency Recognition Using Lightweight CNN Architectures
---------------------------------------------------
In this paper, the authors have avant-grade convolutional neural network (CNN) models with transfer learning to classify Bangladeshi currency. They used publicly available dataset and obtained an accuracy of 99.97%.

# Paper 5: 2021 (CUET)
Bangladeshi Banknote Recognition in Real-time 
using Convolutional Neural Network for Visually
Impaired People
---------------------------------------------------
In this paper, the authors have created a CNN model for the identification of Bangladeshi banknotes belonging to 8 classes. They have created a dataset containing more than 70k images. The average accuracy of their system is 92%.

# Paper 3: 2021 (KUET)
Real-Time Bangladeshi Currency
Recognition Using Faster R-CNN
Approach for Visually Impaired People
---------------------------------------------------
In this research, the authors have used pre-trained faster R-CNN inception V2 coco-2018 model for Bangladeshi currency recognition. They have tested their model on their own dataset consisting of 4507 images. The accuracy of their model is 97.8%.

# Paper 6: 2020 (SUST)
Deep Learning Approach Combining Lightweight
CNN Architecture with Transfer Learning: An
Automatic Approach for the Detection and
Recognition of Bangladeshi Banknotes
---------------------------------------------------
In this paper, the authors have used lightweight CNN architectures (ResNet152v2, MobileNet, and NASNetMobile) in combination with transfer learning. They have used 2 datasets, the Bangla Money dataset (1970 images) and the Bangla Currency dataset (8000) images.
They have achieved maximum test accuracy of 98.88% on the Bangla currency dataset using MobileNet, 100% on the Bangla Money dataset using NASNetMobile, and 97.77% on the combined dataset.

# Paper 7: 2019 (BUET)
Developing a Bangla Currency Recognizer for
Visually Impaired People
---------------------------------------------------
The authors have used MobileNet architecture in their novel dataset consisting of 8000 images of 8 categories note. They achieved a maximum accuracy of 99.81% in validation and 99.80% in testing.
